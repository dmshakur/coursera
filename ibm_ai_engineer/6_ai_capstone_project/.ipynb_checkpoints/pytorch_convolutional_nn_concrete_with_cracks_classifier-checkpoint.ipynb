{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from timeit import Timer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torch.nn.init import kaiming_normal_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('GeForce MX150', 0)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0), torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Data(Dataset):\n",
    "#     def __init__(self, transforms, train = False):\n",
    "#         self.x = torch.zeros(1)\n",
    "#         self.y = torch.zeros(1)\n",
    "        \n",
    "#         negative_file_path = os.path.join('concrete_class/', 'Negative')\n",
    "#         negative_files = [file for file in os.listdir(negative_file_path) if file.endswith('.jpg')]\n",
    "#         negative_files.sort()\n",
    "#         positive_file_path = os.path.join('concrete_class/', 'Positive')\n",
    "#         positive_files = [file for file in os.listdir(positive_file_path) if file.endswith('.jpg')]\n",
    "#         positive_files.sort()\n",
    "#         print(negative_files[0], type(negative_files[0]))\n",
    "        \n",
    "#         if train:\n",
    "#             self.x = torch.zeros(36000, 1)\n",
    "#             for i in range(36000):\n",
    "#                 self.x[i] = transforms(negative_files[i]) if i < 18000 else transforms(negative_files[i])\n",
    "#             self.y = torch.zeros(36000, 1, dtype = 'uint8')\n",
    "#             self.y[18000:, :] = 1\n",
    "#         else:\n",
    "#             self.x = torch.zeros(4000, 1)\n",
    "#             for i in range(4000):\n",
    "#                 self.x[i] = transforms(negative_files[i + 36000]) if i < 2000 else transforms(negative_files[i + 38000])\n",
    "#             self.y = torch.zeros(4000, 1, dtype = 'uint8')\n",
    "#             self.y[2000:, :] = 1\n",
    "        \n",
    "#     def __getitem__(self, index):\n",
    "#         return self.y[index], self.x[index]\n",
    "#     def __len__(self):\n",
    "#         return self.y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, out_1 = 16, out_2 = 32, out_3 = 64):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = out_1, kernel_size = 5)\n",
    "        # self.drop2d1 = nn.Dropout2d(p = 0.35, inplace = True)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size = 2, stride = 1)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(out_1, momentum = 0.5)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels = out_1, out_channels = out_2, kernel_size = 5)\n",
    "        # self.drop2d2 = nn.Dropout2d(p = 0.35, inplace = True)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size = 2, stride = 1)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(out_2, momentum = 0.5)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels = out_2, out_channels = out_3, kernel_size = 5)\n",
    "        # self.drop2d3 = nn.Dropout2d(p = 0.35, inplace = True)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size = 2, stride = 1)\n",
    "        self.batch_norm3 = nn.BatchNorm2d(out_3, momentum = 0.5)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.linear1 = nn.Linear(2876416, 200)\n",
    "        self.drop1 = nn.Dropout(p = 0.35, inplace = True)\n",
    "        self.linear2 = nn.Linear(200, 100)\n",
    "        self.drop2 = nn.Dropout(p = 0.35, inplace = True)\n",
    "        self.linear_output = nn.Linear(100, 10)\n",
    "\n",
    "        kaiming_normal_(self.conv1.weight, nonlinearity = 'relu')\n",
    "        kaiming_normal_(self.conv2.weight, nonlinearity = 'relu')\n",
    "        kaiming_normal_(self.linear1.weight, nonlinearity = 'relu')\n",
    "        kaiming_normal_(self.linear2.weight, nonlinearity = 'relu')\n",
    "        kaiming_normal_(self.linear_output.weight, nonlinearity = 'relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        # x = self.drop2d1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        # x = self.drop2d2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        # x = self.drop2d3(x)\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.batch_norm3(x)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = self.linear1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.drop1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.drop2(x)\n",
    "        x = self.linear_output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, train_loader, val_loader, epochs):\n",
    "    loss_acc = {'training_loss': [], 'training_acc': [], 'validation_loss': [], 'validation_acc': []}\n",
    "    for epoch in range(epochs):\n",
    "        tr_time = Timer()\n",
    "        tr_acc = 0\n",
    "        val_acc = 0\n",
    "        \n",
    "        for i, (x, y) in enumerate(train_loader):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            z = model.forward(x)\n",
    "            tr_loss = criterion(z, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_acc.training_loss.append(tr_loss)\n",
    "            \n",
    "        tr_acc = 100 * (tr_acc / len(train_loader))\n",
    "        loss_acc.training_acc.append(tr_acc)\n",
    "        \n",
    "        val_time = Timer()\n",
    "        for x, y in validation_loader:\n",
    "            model.eval()\n",
    "            z = model(x)\n",
    "            val_loss = criterion(z, y)\n",
    "            _, y_hat = torch.max(z, 1)\n",
    "            val_acc += (y_hat == y).sum().item()\n",
    "            loss_acc.validation_loss.append(val_loss)\n",
    "            \n",
    "        val_acc = 100 * (val_acc / len(train_loader))\n",
    "        loss_acc.validation_acc.append(val_acc)\n",
    "        print('Epoch: {}, training accuracy/time: {}, {}, validation accuracy/time: {}, {}'\n",
    "              .format(epoch, tr_acc, tr_time.timeit(), val_acc, val_timer.timeit()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToCudaTensor(transforms.ToTensor):\n",
    "    def __call__(self, image):\n",
    "        img = np.asarray(image)\n",
    "        img = img.reshape((3, 227, 227))\n",
    "        return torch.from_numpy(img).float().to(0)\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer = transforms.ToTensor()\n",
    "# train_data = Data(transforms = transformer, train = True)\n",
    "# val_data = Data(transforms = transformer, train = False)\n",
    "images = datasets.ImageFolder(root = 'concrete_class/', transform = ToCudaTensor())\n",
    "\n",
    "train_loader = DataLoader(images, shuffle = True)\n",
    "val_loader = DataLoader(images, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 227, 227]),\n",
       " (tensor([[[178., 175., 170.,  ..., 170., 180., 177.],\n",
       "           [172., 181., 178.,  ..., 179., 174., 180.],\n",
       "           [179., 174., 171.,  ..., 189., 186., 179.],\n",
       "           ...,\n",
       "           [173., 168., 173.,  ..., 182., 177., 174.],\n",
       "           [162., 158., 155.,  ..., 152., 163., 159.],\n",
       "           [156., 167., 163.,  ..., 176., 171., 178.]],\n",
       "  \n",
       "          [[175., 170., 176.,  ..., 181., 176., 173.],\n",
       "           [164., 160., 157.,  ..., 152., 163., 159.],\n",
       "           [156., 167., 163.,  ..., 178., 173., 182.],\n",
       "           ...,\n",
       "           [171., 177., 176.,  ..., 174., 171., 176.],\n",
       "           [172., 169., 176.,  ..., 179., 175., 172.],\n",
       "           [151., 150., 146.,  ..., 170., 178., 177.]],\n",
       "  \n",
       "          [[173., 180., 179.,  ..., 172., 169., 174.],\n",
       "           [170., 167., 176.,  ..., 177., 173., 170.],\n",
       "           [161., 160., 156.,  ..., 168., 177., 176.],\n",
       "           ...,\n",
       "           [168., 164., 161.,  ..., 171., 177., 174.],\n",
       "           [169., 173., 170.,  ..., 170., 165., 176.],\n",
       "           [175., 170., 187.,  ..., 173., 169., 166.]]], device='cuda:0'),\n",
       "  0))"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(images[0][0]), images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Negative', 'Positive']"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.14 GiB (GPU 0; 2.00 GiB total capacity; 322.63 MiB already allocated; 936.88 MiB free; 376.00 MiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-331-5e46de15e4a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Source-Files\\anaconda3\\envs\\panthera_uncia\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mcuda\u001b[1;34m(self, device)\u001b[0m\n\u001b[0;32m    305\u001b[0m             \u001b[0mModule\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         \"\"\"\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Source-Files\\anaconda3\\envs\\panthera_uncia\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Source-Files\\anaconda3\\envs\\panthera_uncia\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    223\u001b[0m                 \u001b[1;31m# `with torch.no_grad():`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m                     \u001b[0mparam_applied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Source-Files\\anaconda3\\envs\\panthera_uncia\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    305\u001b[0m             \u001b[0mModule\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         \"\"\"\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.14 GiB (GPU 0; 2.00 GiB total capacity; 322.63 MiB already allocated; 936.88 MiB free; 376.00 MiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "model.cuda(0)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, criterion, optimizer, train_loader, val_loader, epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
