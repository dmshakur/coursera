{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASE STUDY - unsupervised learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import imblearn.pipeline as pl\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE, SVMSMOTE\n",
    "    \n",
    "plt.style.use('seaborn')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synopsis\n",
    "\n",
    "  > We are now going to predict customer retention.  There are many models and many transforms to consider.  Use your\n",
    "    knowledge of pipelines and functions to ensure that your code makes it easy to compare and iterate.  \n",
    "    \n",
    "  > Marketing has asked you to make a report on customer retention.  They would like you to come up with information     that can be used to improve current marketing strategy efforts.  The current plan is for marketing at AAVAIL to\n",
    "    collect more features on subscribers the and they would like to use your report as a proof-of-concept in order to     get buyin for this effort.\n",
    "  \n",
    "## Outline\n",
    "\n",
    "1. Create a churn prediction baseline model\n",
    "2. Use clustering as part of your prediction pipeline\n",
    "3. \n",
    "4. Run and experiment to see if re-sampling techniques improve your model\n",
    "\n",
    "## Data\n",
    "\n",
    "Here we load the data as we have already done.\n",
    "\n",
    "`aavail-target.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing_data(df):\n",
    "    md = dict()\n",
    "    md['isnan'] = df.isna().sum().sum()\n",
    "    md['isnull'] = df.isnull().sum().sum()\n",
    "    md['repeated'] = df.duplicated().sum()\n",
    "    return md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'isnan': 0, 'isnull': 0, 'repeated': 262}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"aavail-target.csv\")\n",
    "\n",
    "## pull out the target and remove uneeded columns\n",
    "_y = df.pop('is_subscriber')\n",
    "y = np.zeros(_y.size)\n",
    "y[_y==0] = 1 \n",
    "df.drop(columns=['customer_id','customer_name'],inplace=True)\n",
    "check_missing_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 1\n",
    "\n",
    "Create a stratified train test split of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size = 0.25, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>age</th>\n",
       "      <th>subscriber_type</th>\n",
       "      <th>num_streams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>united_states</td>\n",
       "      <td>36</td>\n",
       "      <td>aavail_unlimited</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>united_states</td>\n",
       "      <td>35</td>\n",
       "      <td>aavail_unlimited</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>united_states</td>\n",
       "      <td>20</td>\n",
       "      <td>aavail_basic</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>singapore</td>\n",
       "      <td>19</td>\n",
       "      <td>aavail_unlimited</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>united_states</td>\n",
       "      <td>24</td>\n",
       "      <td>aavail_premium</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>singapore</td>\n",
       "      <td>40</td>\n",
       "      <td>aavail_premium</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>united_states</td>\n",
       "      <td>46</td>\n",
       "      <td>aavail_basic</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>united_states</td>\n",
       "      <td>23</td>\n",
       "      <td>aavail_premium</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>united_states</td>\n",
       "      <td>37</td>\n",
       "      <td>aavail_basic</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>united_states</td>\n",
       "      <td>26</td>\n",
       "      <td>aavail_unlimited</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           country  age   subscriber_type  num_streams\n",
       "597  united_states   36  aavail_unlimited           25\n",
       "279  united_states   35  aavail_unlimited           14\n",
       "252  united_states   20      aavail_basic           15\n",
       "599      singapore   19  aavail_unlimited           11\n",
       "298  united_states   24    aavail_premium           20\n",
       "..             ...  ...               ...          ...\n",
       "689      singapore   40    aavail_premium           13\n",
       "786  united_states   46      aavail_basic           16\n",
       "531  united_states   23    aavail_premium           19\n",
       "964  united_states   37      aavail_basic           20\n",
       "904  united_states   26  aavail_unlimited           22\n",
       "\n",
       "[750 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 2\n",
    "\n",
    "Create a baseline model.  We are going to test whether clustering followed by a model improves the results.  The we will test whether re-sampling techniques provide improvements.  Use a pipeline or another method, but create a baseline model given the data. Here is the ColumnTransformer we have used before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_cols = ['country', 'subscriber_type']\n",
    "scale_cols = ['age', 'num_streams']\n",
    "\n",
    "one_hot = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown = 'ignore'))\n",
    "])\n",
    "\n",
    "scaler = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy = 'mean')),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('one_hot_pipeline', one_hot, one_hot_cols),\n",
    "    ('scaler_pipeline', scaler, scale_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pre = preprocessor.fit_transform(X_train)\n",
    "X_test_pre = preprocessor.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  1.        ,  0.        , ...,  1.        ,\n",
       "         0.8799322 ,  1.50628234],\n",
       "       [ 0.        ,  1.        ,  0.        , ...,  1.        ,\n",
       "         0.80257325, -0.77136233],\n",
       "       [ 0.        ,  1.        ,  1.        , ...,  0.        ,\n",
       "        -0.3578109 , -0.56430372],\n",
       "       ...,\n",
       "       [ 0.        ,  1.        ,  0.        , ...,  0.        ,\n",
       "        -0.12573407,  0.2639307 ],\n",
       "       [ 0.        ,  1.        ,  1.        , ...,  0.        ,\n",
       "         0.95729114,  0.47098931],\n",
       "       [ 0.        ,  1.        ,  0.        , ...,  1.        ,\n",
       "         0.10634276,  0.88510652]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          1.          1.          0.          0.         -0.80012161\n",
      " -0.98141587]\n"
     ]
    }
   ],
   "source": [
    "print(X_test_pre[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 3\n",
    "\n",
    "The next part is to create version of the classifier that uses identified clusters.  Here is a class to get you started.  It is a transformer like those that we have been working with.  There is an example of how to use it just below.  In this example 4 clusters were specified and their one-hot encoded versions were appended to the feature matrix.  Now using pipelines and/or functions compare the performance using cluster profiling as part of your matrix to the baseline.  You may compare multiple models and multiple clustering algorithms here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class LogisticClf():\n",
    "    def __init__(self, penalty = 'l2', solver = 'liblinear', C = 1.0):\n",
    "        self.log_model = LogisticRegression(penalty = penalty, solver = solver, C = C)\n",
    "        self.score = None\n",
    "        self.predictions = None\n",
    "    def fit(self, X, y):\n",
    "        self.log_model.fit(X, y)\n",
    "    def predict(self, X):\n",
    "        self.log_model = self.log_model.predict(X)\n",
    "\n",
    "class KmeansClf():\n",
    "    def __init__(self, n_clusters = 2, n_init = 10):\n",
    "        self.kmeans = KMeans(n_clusters = n_clusters, n_init = n_init)\n",
    "        self.predictions = None\n",
    "    def fit_transform(self, X, y):\n",
    "        self.kmeans.fit_transform(X, y)\n",
    "    def pred(self, X):\n",
    "        self.predictions = self.kmeans.predict(X)\n",
    "        return self.predictions\n",
    "        \n",
    "class RandomForestClf():\n",
    "    def __init__(self, max_depth = None, random_state = 0):\n",
    "        self.random_forest = RandomForestClassifier(max_depth = max_depth, random_state = random_state)\n",
    "        self.predictions = None\n",
    "    def fit(self, X, y):\n",
    "        self.random_forest.fit(X, y)\n",
    "    def pred(self, X):\n",
    "        pred = self.random_forest.predict(X)\n",
    "        self.predictions = pred\n",
    "        return pred\n",
    "    \n",
    "class SpectralClusteringClf():\n",
    "    def __init__(self, n_clusters = 2, random_state = 0):\n",
    "        self.spectral_clustering = SpectralClustering(n_clusters = n_clusters, random_state = random_state)\n",
    "        self.predictions = None\n",
    "    def fit(self, X, y):\n",
    "        self.spectral_clustering.fit(X, y)\n",
    "    def pred(self, X):\n",
    "        pred = self.spectral_clustering.predict(X)\n",
    "        self.predictions = pred\n",
    "        return pred\n",
    "    \n",
    "class BayesGaussianMixClf():\n",
    "    def __init__(self):\n",
    "        self.bayes_gauss = BayesianGaussianMixture()\n",
    "        self.predictions = None\n",
    "    def fit(self, X, y):\n",
    "        self.bayes_gauss.fit(X, y)\n",
    "    def pred(self, X):\n",
    "        pred = self.bayes_gauss.predict(X)\n",
    "        self.predictions = pred\n",
    "        return pred\n",
    "\n",
    "def compare_all_methods(X, y, X_test, y_test):\n",
    "    kmeans = KMeans(n_clusters = 2, n_init = 10)\n",
    "    kmeans.fit_transform(X, y)\n",
    "    rand_forest = RandomForestClassifier(random_state = 0)\n",
    "    rand_forest.fit(X, y)\n",
    "    bayes_gauss = BayesianGaussianMixture()\n",
    "    bayes_gauss.fit(X, y)\n",
    "    log_reg = LogisticRegression()\n",
    "    log_reg.fit(X, y)\n",
    "    predictions = {\n",
    "        'kmeans': kmeans.predict(X_test),\n",
    "#         'kmeans_model': kmeans,\n",
    "        'rand_forest': rand_forest.predict(X_test),\n",
    "#         'rand_forest_model': rand_forest,\n",
    "#         'spect_clust': spect_clust.predict(X_test),\n",
    "#         'spect_clust_model': spect_clust,\n",
    "        'bayes_gauss': bayes_gauss.predict(X_test),\n",
    "#         'bayes_gauss_model': bayes_gauss,\n",
    "        'log_reg': log_reg.predict(X_test),\n",
    "#         'log_reg_model': log_reg\n",
    "    }\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = compare_all_methods(X_train_pre, y_train, X_test_pre, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.75      0.76       178\n",
      "         1.0       0.41      0.43      0.42        72\n",
      "\n",
      "    accuracy                           0.66       250\n",
      "   macro avg       0.59      0.59      0.59       250\n",
      "weighted avg       0.66      0.66      0.66       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions['kmeans']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.84      0.81       178\n",
      "         1.0       0.53      0.46      0.49        72\n",
      "\n",
      "    accuracy                           0.73       250\n",
      "   macro avg       0.66      0.65      0.65       250\n",
      "weighted avg       0.72      0.73      0.72       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions['rand_forest']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      1.00      0.83       178\n",
      "         1.0       0.00      0.00      0.00        72\n",
      "\n",
      "    accuracy                           0.71       250\n",
      "   macro avg       0.36      0.50      0.42       250\n",
      "weighted avg       0.51      0.71      0.59       250\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dangelo/source_files/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions['bayes_gauss']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUESTION 4\n",
    "\n",
    "Run an experiment to see if you can you improve on your workflow with the addition of re-sampling techniques?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SMOTE' object has no attribute '_validate_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-56b528b5ec6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_re\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_re\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_pre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompare_all_modelx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_re\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/source_files/anaconda3/lib/python3.7/site-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0marrays_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArraysTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         self.sampling_strategy_ = check_sampling_strategy(\n",
      "\u001b[0;32m~/source_files/anaconda3/lib/python3.7/site-packages/imblearn/base.py\u001b[0m in \u001b[0;36m_check_X_y\u001b[0;34m(self, X, y, accept_sparse)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0maccept_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_target_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicate_one_vs_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SMOTE' object has no attribute '_validate_data'"
     ]
    }
   ],
   "source": [
    "X_re, y_re = SMOTE().fit_sample(X_train_pre, y_train)\n",
    "predictions = compare_all_modelx(X_re, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
