{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenScale Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, let's start by creating the predictive model. \n",
    "This is a text classfier to predict customer churn based on movie reviews. We'll use the same data as we did in Module 4.\n",
    "\n",
    "The input data is plain text of movie reviews. We'll first clean, tokenize and lemmatize the words, then convert them to a numeric matrix of tf-idf.\n",
    "\n",
    "We'll do this in two parts, so that the deployed model can have a numeric feature matrix as its input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sklearn\n",
    "import pickle\n",
    "import sys\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from string import punctuation, printable\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review  label\n",
      "0  b\"arnold schwarzenegger has been an icon for a...      0\n",
      "1  b\"good films are hard to find these days . \\ng...      1\n",
      "2  b\"quaid stars as a man who has taken up the pr...      1\n",
      "3  b'we could paraphrase michelle pfieffer\\'s cha...      0\n",
      "4  b\"kolya is one of the richest films i've seen ...      1\n"
     ]
    }
   ],
   "source": [
    "movie_reviews = pd.read_csv('movie_reviews.csv')\n",
    "print(movie_reviews.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = movie_reviews['review']\n",
    "y = movie_reviews['label'].rename('*label*')\n",
    "\n",
    "# The target column must have a name that does not appear as a word/token in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up and convert the plain text\n",
    "good_characters = 'abcdefghijklmnopqrstuvwxyz '\n",
    "def lemmatize(doc):    \n",
    "    doc = str(doc).lower()\n",
    "    doc = \"\".join([char for char in doc if char in good_characters])\n",
    "    doc = nlp(doc)\n",
    "    tokens = [re.sub(\"\\W+\",\"\",token.lemma_.lower()) for token in doc ]\n",
    "    return ' '.join(w for w in tokens if (w not in ENGLISH_STOP_WORDS) and (len(w)>1))\n",
    "\n",
    "X = X.apply(lemmatize)\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = [data.reset_index(drop = True) for \n",
    "                                    data in train_test_split(X,y, random_state = 101)]\n",
    "\n",
    "print(X_train.head(), X_test.head(), y_train.head(), y_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer(max_features = 10000).fit(X_train)\n",
    "X_train_tfidf = tf_idf.transform(X_train).todense()\n",
    "X_test_tfidf = tf_idf.transform(X_test).todense()\n",
    "X_train_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The vocabulary in the tf_idf is an unordered dictionary.\n",
    "# we need to sort it so that we can associate words with coefficients\n",
    "words = []\n",
    "indices = []\n",
    "for word, index in tf_idf.vocabulary_.items():\n",
    "    words.append(word)\n",
    "    indices.append(index)\n",
    "    \n",
    "sorted_index = np.argsort(indices)\n",
    "sorted_words = np.array(words)[sorted_index]\n",
    "print(sorted_words, len(sorted_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the tf-idf (numeric) array to a pandas dataframe with feature columns\n",
    "X_train_df = pd.DataFrame(X_train_tfidf)\n",
    "X_test_df = pd.DataFrame(X_test_tfidf)\n",
    "X_train_df.columns = sorted_words\n",
    "X_test_df.columns = sorted_words\n",
    "X_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We have converted our plain text to a dense DataFrame of tf-idf for the top 10,000 terms. \n",
    "\n",
    "### You will notice that nearly all of the cells are zero, and many of the words don't seem to be relevant to whether or not a customer is likely to churn. Words like \"awful\" and \"wonderful\" are likely correlated with customer satisfaction, but the implcation of words like 'zombie' and 'zoolander' are not as obvious.\n",
    "\n",
    "### To reduce the complexity of the model, we will identify the 200 most significant words and rebuild a model just using these. Note that *most significant* does not mean most common -- it means the words that have the highest magnitude coefficient in the predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SGDClassifier(loss = 'log', max_iter = 1000).fit(X_train_df, y_train)\n",
    "print('Training score: ', model.score(X_train_df, y_train))\n",
    "print('Test score: ', model.score(X_test_df, y_test))\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, model.predict(X_test_df)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_of_positive_features = np.argsort(model.coef_)[0][::-1][:100]\n",
    "indices_of_negative_features = np.argsort(model.coef_)[0][:100]\n",
    "\n",
    "vocabulary = np.array(sorted_words)\n",
    "positive_vocab = vocabulary[indices_of_positive_features]\n",
    "negative_vocab = vocabulary[indices_of_negative_features]\n",
    "print('20 most positive words: \\n', positive_vocab[:20])\n",
    "print('20 most negative words: \\n', negative_vocab[:20])\n",
    "significant_vocabulary = np.hstack([positive_vocab, negative_vocab])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review of signficant words\n",
    "Reviewing the list of signficant words shown above, in the \"good words\" category, we find 'great' 'fun' 'hilarious' 'good' 'terrific' 'excellent' 'memorable' 'perfect' (among many others)\n",
    "\n",
    "In the category of 'bad words', there is 'bad' 'waste' 'boring' 'fail' 'stupid' 'lame' 'nunfortunately' 'poor' 'dull' 'ridiculous' 'bore' 'awful'  'terrible' 'mess' (among many others)\n",
    "\n",
    "In other words, there is a strong and intuitive link between the words customers use in written reviews and their liklihood to remain a customer. \n",
    "\n",
    "In terms of *Business Opportunity* these findings are not unexecpted. This provides important validation of a mathematical and measureable link between customer sentiment and business opportunities.\n",
    "\n",
    "This gives me confidence that our model has correctly identifed words associated with positive and negative outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Having found the most siginficant words, let us now build a TF-IDF Vectorizer focused only on these words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_tfidf = TfidfVectorizer(vocabulary = significant_vocabulary).fit(X_train)\n",
    "X_train_significant_tfidf = significant_tfidf.transform(X_train).todense()\n",
    "X_test_significant_tfidf = significant_tfidf.transform(X_test).todense()\n",
    "print(X_train_significant_tfidf)\n",
    "print(X_train_significant_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save this trained TF-IDF Vectorizer for future use\n",
    "with open('significant_tfidf.pkl', 'wb') as f:\n",
    "    pickle.dump(significant_tfidf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_significant_df = pd.DataFrame(X_train_significant_tfidf)\n",
    "X_test_significant_df = pd.DataFrame(X_test_significant_tfidf)\n",
    "X_train_significant_df.columns = significant_tfidf.vocabulary_\n",
    "X_test_significant_df.columns = significant_tfidf.vocabulary_\n",
    "X_train_significant_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the training data, with `*label*` column.\n",
    "\n",
    "## We will need this later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([X_train_significant_df, y_train], axis =1).to_csv('training_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's now train a SGDClassifier using this smaller, more select data set and see how it performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_model = SGDClassifier(loss = 'log', max_iter = 1000).fit(X_train_significant_df, y_train)\n",
    "print('Training score: ', significant_model.score(X_train_significant_df, y_train))\n",
    "print('Test score: ', significant_model.score(X_test_significant_df, y_test))\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, significant_model.predict(X_test_significant_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On the test data, this preforms almost exactly as well as the orignal model which had 10,000 feature words, but this one has only 200 feature words -- it uses 98% less data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that we have a reasonably good model, let's deploy it to IBM Watson ML\n",
    "You should already have an account with Watson Studio and credentials saved in ```~/.ibm/wml.json```.\n",
    "\n",
    "If you need to create these credentials, please revisit the tutorial in Module 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import credentials from ~/.ibm/wml.json\n",
    "wmlcreds_file = os.path.join(os.path.expanduser(\"~\"),'.ibm/wml.json')\n",
    "# or set location of file manually:\n",
    "wmlcreds_file = wmlcreds_file #replace with location of file if different than ~/.ibm/wml.json\n",
    "with open(wmlcreds_file, \"r\") as wml_file:\n",
    "        wmlcreds = json.load(wml_file)\n",
    "\n",
    "# convert credentials to the correct dictoinary format\n",
    "wml_credentials = {\"apikey\": wmlcreds['apikey'],\n",
    "    \"instance_id\": wmlcreds['instance_id'],\n",
    "    \"url\": wmlcreds['url'],}\n",
    "\n",
    "print(wml_credentials.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a client to interact with Watson Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient\n",
    "client = WatsonMachineLearningAPIClient(wml_credentials)\n",
    "print(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review deployed models and delete any unused models to make room for new deployments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.repository.list_models()\n",
    "# guid = 'Insert guid to delete here'\n",
    "# client.repository.delete(guid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's store the Model in the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {client.repository.ModelMetaNames.NAME: \"Model200\",\n",
    "client.repository.ModelMetaNames.FRAMEWORK_NAME: \"scikit-learn\",\n",
    "client.repository.ModelMetaNames.FRAMEWORK_VERSION: sklearn.__version__}\n",
    "model_details = client.repository.store_model(significant_model, meta_props=metadata)\n",
    "\n",
    "model_uid = client.repository.get_model_uid(model_details)\n",
    "\n",
    "client.repository.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And now we deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_details = client.deployments.create(artifact_uid=model_uid, \n",
    "                                               name=\"Model1-deployment\")\n",
    "deployment_uid = deployment_details['metadata']['guid']\n",
    "print(deployment_uid)\n",
    "print(client.deployments.get_status(deployment_uid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We should now see a model and the corresponding online deployment\n",
    "client.repository.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's verify the deployment by sending it some data and getting a response\n",
    "\n",
    "Let's send it a movie review and see if it thinks we are likely to churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_movie_review = \"This movie is really good. I really liked it. I want to watch it again. Excellent!\"\n",
    "# movie_review = \"bad hated terrible awful horrible never\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatize and tf-idf the text.\n",
    "As before, we can't just send plain text like this. It needs to be cleaned, lemmatized and converted to a tf-idf numeric matrix, using the same methods that the model was first trained on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_movie_review = lemmatize(good_movie_review)\n",
    "good_movie_review = significant_tfidf.transform([good_movie_review]).todense()\n",
    "good_movie_review = pd.DataFrame(good_movie_review)\n",
    "good_movie_review.columns = significant_tfidf.vocabulary_\n",
    "print(good_movie_review.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can now create a data payload and send this to the deployed model for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = good_movie_review.values.tolist()\n",
    "payload = {'fields':list(significant_tfidf.vocabulary_), 'values': values}\n",
    "scoring_url = deployment_details['entity']['scoring_url']\n",
    "prediction = client.deployments.score(scoring_url, payload)\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's do the same with a bad movie review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_review = \"I really hated this bad movie. it was awful. I want to quit. Horrible. terrible\"\n",
    "bad_review = lemmatize(bad_review)\n",
    "bad_review = significant_tfidf.transform([bad_review]).todense()\n",
    "bad_review = pd.DataFrame(bad_review)\n",
    "bad_review.columns = significant_tfidf.vocabulary_\n",
    "print(bad_review.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = bad_review.values.tolist()\n",
    "payload = {'fields':list(significant_tfidf.vocabulary_), 'values': values}\n",
    "scoring_url = deployment_details['entity']['scoring_url']\n",
    "prediction = client.deployments.score(scoring_url, payload)\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As you can see, we get a very different prediction for the bad review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenScale Configuration\n",
    "## The next step is to link this deployed model to IBM Watson OpenScale to provide monitoring services\n",
    "\n",
    "To get started, navigate to your `Dashboard` at https://cloud.ibm.com/\n",
    "\n",
    "At the upper right, click on `Create Resource`. This will take you to the catalog of services offered in the IBM Watson Suite. We'll be using ``Watson OpenScale``, but you might want to take a minute to examine some of the many other offerings.\n",
    "\n",
    "You can also use this link to take you directly to the OpenScale service: \n",
    "\n",
    "https://cloud.ibm.com/catalog/services/watson-openscale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the service\n",
    "If you're using the free lite plan, accept the default. You may change the `Service name` if you wish. In this example, I am calling my service `'OS-tutorial'`\n",
    "\n",
    "On the right, click `Create` and then `'Launch Applicaton'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the service\n",
    "You should now see the welcome message as shown below.\n",
    "![Welcome message](images/os_tutorial_1.png)\n",
    "\n",
    "\n",
    "Click on `Auto setup`\n",
    "\n",
    "It will take a few minutes as OpenScale configures some default services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the Auto setup is complete, you should see the following dialog:\n",
    "![All set](images/os_tutorial_2.png)\n",
    "\n",
    "Click on `start tour`\n",
    "\n",
    "The tour shows the German Credit Risk model as an example. You may spend some time exploring this. This example address issues such as fairness by gender, which is an important consideration in many models, especially where historically different demographic groups have been discriminated against.\n",
    "\n",
    "In this model, the effect of gender or other demographic features is monitored by creating synthetic inputs in which all the data is the same except the demographic value has been altered, and then determining if a more favorable outcome would have resulted. This is equivalent to calculating the partial derivative with respect to the demographic value at a particular point in the response curve.\n",
    "\n",
    "It can then suggest, and even auto-generate models that are demonstrable more fair.\n",
    "\n",
    "OpenScale can also look for, and automatically address, selection bias and demographic imbalance in the training data set.\n",
    "\n",
    "On a a more granular level, OpenScale can examine the decision-making process behind individual transactions, provide *explainability* for the outcome and assess fairness. It can also provide a list of the minimum changes necessary to alter the outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are done examing the Credit Risk example, we will delete it and replace it with our churn-prediction model. Our model does not have a feature describing gender, race or other demographics, so some of the issues of fairness are not relevant.\n",
    "\n",
    "Return to the Insights Dashboard and click on the *heart beat* (zig-zag) icon at the upper left.\n",
    "![insights dashboard](images/os_tutorial_4.png)\n",
    "\n",
    "You should see the tile for the GermanCreditRiskModel_Application\n",
    "\n",
    "Click on the drop-down list and select `Remove Application`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, go to the `Model Monitors` tab where you will see the tile 'GermanCreditRisk'. Again, select 'Remove Deployment' from the drop down list on this tile.\n",
    "\n",
    "You should now see an empty Insights Dashboard and a message that says, \"Add a deployed model to get started.\"\n",
    "\n",
    "Click on `Add`\n",
    "\n",
    "In the dialog box, select the churn prediction model we deployed previously in this tutorial and click `configure`.\n",
    "\n",
    "On the next screen, click `configure monitors`.\n",
    "\n",
    "Our data type is `numeric/categorical`, which may be the only option available, and our algorithim type is `Binary classification`.\n",
    "\n",
    "Click `save`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Payload Logging\n",
    "On the next screen, you should see the following message about Payload logging.\n",
    "![payload logging](images/os_tutorial_5.png).\n",
    "\n",
    "OpenScale needs to see an example of what the incoming data is expected to look like. So we need to send some example payloads for configuration.\n",
    "\n",
    "Also on this page, you will see the details of the deployment and subscription and be able to download them as a json file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send a scoring request\n",
    "To send a score request, we need several things, a url of the deployed model, a client to send the data from python to the model and a payload or set of input data.\n",
    "\n",
    "We created the WatsonMachineLearningAPIClient earlier in this tutorial\n",
    "\n",
    "We'll use the same payload and scoring url as above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send the payload for scoring and print the results\n",
    "predictions = client.deployments.score(scoring_url, payload)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Return results\n",
    "When our payload has been sent sucessfully, we should see the results returned. These include the predictions (in this case, 1 for the first review and 0 for the second review), along with the corresponding predicted probabilities.\n",
    "\n",
    "When this has been completed, return to the `Payload Logging` page and click `I'm finished` to complete the process.\n",
    "\n",
    "You should then see the message, `Logging Activated Sucessfully`\n",
    "\n",
    "![logging activated sucessfully](images/os_tutorial_6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Details Setup\n",
    "\n",
    "You will now need to complete the model details setup.\n",
    "\n",
    "Click on `model details` at the left and then, on the next screen, click `begin`\n",
    "\n",
    "You have two options, `Manually configure monitors` and `Upload training data distribution`. We will manually configure the monitors.\n",
    "\n",
    "Select this option and click `next`. \n",
    "![Upload Training Data](images/os_tutorial_7a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify the location of the training data.\n",
    "\n",
    "### We now need to create a Cloud Storage Object to store the training data.\n",
    "\n",
    "You may review your list of resources using the following link:\n",
    "https://cloud.ibm.com/resources\n",
    "\n",
    "If you do not have a Cloud Object Storage, navigate to:\n",
    "https://cloud.ibm.com/catalog\n",
    "\n",
    "Click `Storage` from the left column and then the tile for `Object Storage`\n",
    "![Cloud Object Storage](images/os_tutorial_8.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the `lite` plan, provide a Service Name (optional), and then click `Create`\n",
    "\n",
    "On the next page, click `Create Bucket`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the option to create a **Custom Bucket**\n",
    "![custom_bucket](images/os_tutorial_9.png)\n",
    "\n",
    "Provide a unique name (for example, one containing your username) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important: Under `Resiliency` make sure you select \"Cross Region\"\n",
    "\n",
    "### Under `Location` select your region.\n",
    "\n",
    "### You may leave the remaining options as default\n",
    "\n",
    "### Click `Create Bucket` at the lower right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Training Data\n",
    "\n",
    "You should now see an empty bucket and a prompt to drag and drop files to upload.\n",
    "![drag and drop files](images/os_tutorial_10.png) \n",
    "\n",
    "Locate the file `training_data.csv` that we created earlier in this tutorial. (It should be located in the same directory as this notebook.)  Drag and drop this to the bucket.\n",
    "\n",
    "It should only take a few moments to upload this data.\n",
    "\n",
    "### Leave this window open. You will need it for connection data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect the Training Data to OpenScale\n",
    "\n",
    "We now need to link the training data in the Cloud Storage bucket to our model in OpenScale.\n",
    "\n",
    "Return to the OpenScale Dashboard. Under `Model Details` it requests, \"Specify the location of the training data.\"\n",
    "\n",
    "Select `Cloud Object Storage` from the drop-down list.\n",
    "\n",
    "To find the `Login URL`, return to the Cloud Object Storage webpage and select `Endpoint` from the column at left.\n",
    "\n",
    "In the drop-down list for `Resiliency`, select `Cross Region` and select your Location from the locations drop-down.\n",
    "![endpoint url](images/os_tutorial_11.png)\n",
    "\n",
    "Select and copy the url for your endpoint. (In this tutorial, I am using us-geo, Public).\n",
    "\n",
    "Return to the webpage for OpenScale and paste this url into `login url`.\n",
    "\n",
    "### Important: you must add \"https://\" to the front of this url."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resource Instance ID\n",
    "\n",
    "To locate your `Resource Instance ID`, return to the Cloud Storage webpage and select `Service Credentials` from the left column.\n",
    "\n",
    "Next, select `New Credentials`.\n",
    "\n",
    "On the `Add New Credential` dialog box, change the Role to `Manager` and click `Add`.\n",
    "\n",
    "When the credentials appear, select `View credentials` under the `Actions` column.\n",
    "\n",
    "You should now see a JSON object including \"apikey\", \"endpoints\", etc.\n",
    "\n",
    "In this JSON, copy the value for resource_instance_id.  Paste this into the `Resource Instance ID` field in the OpenScale webpage.\n",
    "\n",
    "Do the same for the \"apikey\" value in the JSON.\n",
    "\n",
    "When these values have been entered into the OpenScale configuration, select `Test`.\n",
    "\n",
    "After a couple of seconds, you should see: \n",
    "![success](images/os_tutorial_12.png)\n",
    "\n",
    "Click `Next` at the lower right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select your bucket and training data set.\n",
    "\n",
    "From the drop-down lists on the next page, select the bucket and training data set you have uploaded, and then click `Next`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Configuration\n",
    "\n",
    "### OpenScale will now review the training data and associate the column labels.\n",
    "\n",
    "Rememeber that our label column is called `*label*`, so as not to conflict with the word \"label\" if it were to appear in the corpus. OpenScale automatically identifies this column as the label column and asks to confirm. \n",
    "\n",
    "Select this column name and click `Next`\n",
    "\n",
    "![select label data](images/os_tutorial_13.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the features used to train the AI Deployment\n",
    "\n",
    "![feature columns](images/os_tutorial_14.png)\n",
    "\n",
    "\n",
    "OpenScale again automatically identifies the *feature* columns. Make sure these are all selected and click `Next`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select text and categorical features\n",
    "\n",
    "In this model, we do not have any text or categorical features. All of our features have been reduced to a TF-IDF numeric matrix. \n",
    "\n",
    "Leave all these features unselected and click `Next`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the deployment prediction column\n",
    "\n",
    "This refers to the predictions created by our model *not* to a `predictions` column in our data set. Select the `predictions` option and click `Next`.\n",
    "\n",
    "Do the same for `probabiltiy` on the following page.\n",
    "\n",
    "We did not include a transcation ID in this model, so this optional column is left blank.\n",
    "\n",
    "On the final page, review the **Models details summary** and click `Save`\n",
    "\n",
    "After a few seconds, it should say:\n",
    "![model ready](images/os_tutorial_15.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring Drift Monitor\n",
    "\n",
    "The input to our model is plain text. We have not collected demographic information such as race, gender or nationality, so the Fairness monitoring tool is not applicable to this tutorial. \n",
    "\n",
    "We will use the Drift monitoring tool to monitor the deployed model over time.\n",
    "\n",
    "Select `Drift` from the column at left and then `Begin` at lower right\n",
    "![drift](images/os_tutorial_drift1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure accuracy drift monitor\n",
    "\n",
    "Select the option for `Analyze and train in Watson OpenScale` and click `Next`\n",
    "\n",
    "![drift source](images/os_tutorial_drift2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the drift alert threshold\n",
    "    \n",
    "A drift alert threshold of 10% is the defualt. Lower values will make the system more sensitive to small amounts of drift, providing early warning of changes to data.\n",
    "\n",
    "Click `Next`\n",
    "\n",
    "Set the sample size on the next page and click `Next`\n",
    "\n",
    "Review the settings for the Drift monitor on the final page and click `Save`.\n",
    "\n",
    "It may take ten to twenty minutes to configure and train the drift monitor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment Monitoring\n",
    "\n",
    "After the Drift monitor is trained, you can return to the IBM Watson OpenScale dashboard and monitor the performance of the model over time as additional transactions are made.\n",
    "\n",
    "Note that quality and fairness metrics update once per hour and drift updates once every three hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
